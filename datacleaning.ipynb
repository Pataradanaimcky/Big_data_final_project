{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8924470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset_1 = pd.read_csv(\"/Users/yourgrandpaprogenynamesmcky/Developer/Big_data_final_project/Data/AAPL_yfinance_data_20250417.csv\")\n",
    "dataset_2 = pd.read_csv(\"/Users/yourgrandpaprogenynamesmcky/Developer/Big_data_final_project/Data/apple_stock.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "364a5030",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_column = [\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8269c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def clean_date_column_fixed(df, date_column):\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    print(f\"Current dtype of {date_column}: {df_copy[date_column].dtype}\")\n",
    "    print(f\"Sample values from {date_column}:\")\n",
    "    print(df_copy[date_column].head())\n",
    "    \n",
    "    try:\n",
    "        df_copy[date_column] = pd.to_datetime(df_copy[date_column], errors='coerce')\n",
    "        \n",
    "        if df_copy[date_column].isna().any():\n",
    "            print(f\"Warning: Some dates could not be parsed. First few problematic values:\")\n",
    "            problematic = df_copy.loc[df_copy[date_column].isna(), date_column]\n",
    "            print(problematic.head())\n",
    "        \n",
    "        df_copy[date_column] = df_copy[date_column].dt.strftime('%Y-%m-%d')\n",
    "        \n",
    "        return df_copy\n",
    "    \n",
    "    except AttributeError:\n",
    "        print(\"AttributeError occurred. Let's try an alternative approach.\")\n",
    "        \n",
    "        def extract_date_part(date_str):\n",
    "            if pd.isna(date_str):\n",
    "                return None\n",
    "            \n",
    "            date_str = str(date_str)\n",
    "            \n",
    "            if ' ' in date_str:\n",
    "                date_part = date_str.split(' ')[0]\n",
    "                return date_part\n",
    "            return date_str\n",
    "        \n",
    "        df_copy[date_column] = df_copy[date_column].apply(extract_date_part)\n",
    "        print(f\"After alternative processing: {df_copy[date_column].head()}\")\n",
    "        \n",
    "        df_copy[date_column] = pd.to_datetime(df_copy[date_column], errors='coerce')\n",
    "        df_copy[date_column] = df_copy[date_column].dt.strftime('%Y-%m-%d')\n",
    "        \n",
    "        return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16bd638e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dtype of Date: object\n",
      "Sample values from Date:\n",
      "0    2024-04-17 00:00:00-04:00\n",
      "1    2024-04-18 00:00:00-04:00\n",
      "2    2024-04-19 00:00:00-04:00\n",
      "3    2024-04-22 00:00:00-04:00\n",
      "4    2024-04-23 00:00:00-04:00\n",
      "Name: Date, dtype: object\n",
      "AttributeError occurred. Let's try an alternative approach.\n",
      "After alternative processing: 0    2024-04-17\n",
      "1    2024-04-18\n",
      "2    2024-04-19\n",
      "3    2024-04-22\n",
      "4    2024-04-23\n",
      "Name: Date, dtype: object\n",
      "Current dtype of Date: object\n",
      "Sample values from Date:\n",
      "0    1980-12-12\n",
      "1    1980-12-15\n",
      "2    1980-12-16\n",
      "3    1980-12-17\n",
      "4    1980-12-18\n",
      "Name: Date, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8j/0ktshwmn32g805v3mcyjxjgm0000gn/T/ipykernel_75706/3897436818.py:13: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df_copy[date_column] = pd.to_datetime(df_copy[date_column], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "dataset_1_date_cleaned = clean_date_column_fixed(dataset_1, \"Date\").rename(columns={\n",
    "    \"Close*\": \"Close\"\n",
    "})[dataset_column].reset_index(drop=True)\n",
    "\n",
    "dataset_2_date_cleaned = clean_date_column_fixed(dataset_2.rename(columns={\n",
    "    \"Unnamed: 0\": \"Date\"\n",
    "}), \"Date\")[dataset_column].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e569781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-12-12</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>469033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-12-15</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>175884800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-12-16</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>105728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-12-17</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>86441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-12-18</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>73449600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11102</th>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>257.829987</td>\n",
       "      <td>258.700012</td>\n",
       "      <td>253.059998</td>\n",
       "      <td>255.589996</td>\n",
       "      <td>42355300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11103</th>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>252.229996</td>\n",
       "      <td>253.500000</td>\n",
       "      <td>250.750000</td>\n",
       "      <td>252.199997</td>\n",
       "      <td>35557500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11104</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>252.440002</td>\n",
       "      <td>253.279999</td>\n",
       "      <td>249.429993</td>\n",
       "      <td>250.419998</td>\n",
       "      <td>39480700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11105</th>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>248.929993</td>\n",
       "      <td>249.100006</td>\n",
       "      <td>241.820007</td>\n",
       "      <td>243.850006</td>\n",
       "      <td>55558000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11106</th>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>243.369995</td>\n",
       "      <td>244.179993</td>\n",
       "      <td>241.889999</td>\n",
       "      <td>243.860001</td>\n",
       "      <td>15135053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11107 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date        Open        High         Low       Close     Volume\n",
       "0      1980-12-12    0.128348    0.128906    0.128348    0.128348  469033600\n",
       "1      1980-12-15    0.122210    0.122210    0.121652    0.121652  175884800\n",
       "2      1980-12-16    0.113281    0.113281    0.112723    0.112723  105728000\n",
       "3      1980-12-17    0.115513    0.116071    0.115513    0.115513   86441600\n",
       "4      1980-12-18    0.118862    0.119420    0.118862    0.118862   73449600\n",
       "...           ...         ...         ...         ...         ...        ...\n",
       "11102  2024-12-27  257.829987  258.700012  253.059998  255.589996   42355300\n",
       "11103  2024-12-30  252.229996  253.500000  250.750000  252.199997   35557500\n",
       "11104  2024-12-31  252.440002  253.279999  249.429993  250.419998   39480700\n",
       "11105  2025-01-02  248.929993  249.100006  241.820007  243.850006   55558000\n",
       "11106  2025-01-03  243.369995  244.179993  241.889999  243.860001   15135053\n",
       "\n",
       "[11107 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_2_date_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "865f4993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_1_len 252\n",
      "dataset_2_len 11107\n",
      "consolidated_data_len 11178\n"
     ]
    }
   ],
   "source": [
    "consolidated_data = pd.concat([dataset_1_date_cleaned, dataset_2_date_cleaned], axis=0, ignore_index=True).drop_duplicates(subset=[\"Date\"], keep=\"last\").reset_index(drop=True)\n",
    "print(\"dataset_1_len\", len(dataset_1))\n",
    "print(\"dataset_2_len\", len(dataset_2))\n",
    "print(\"consolidated_data_len\", len(consolidated_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a865857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_data.to_csv(\"/Users/yourgrandpaprogenynamesmcky/Developer/Big_data_final_project/Data/final/consolidated_apple_stock_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
